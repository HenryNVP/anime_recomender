{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c73f1a0e",
      "metadata": {
        "id": "c73f1a0e"
      },
      "source": [
        "# Anime Recommender\n",
        "Item-based Collaborative Filtering | Matrix Factorization | Neural Matrix Factorization (NeuMF) | Two-Tower"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d59595",
      "metadata": {
        "id": "d8d59595"
      },
      "source": [
        "✨ Highlights\n",
        "\n",
        "- Models: Matrix Factorization (MF), NeuMF, Two-Tower, and ItemCF baseline.\n",
        "\n",
        "- Objectives: MSE (explicit ratings), BPR (implicit ranking), and MSE→BPR fine-tune.\n",
        "\n",
        "- Reproducible runs: auto-timestamped run dirs, TensorBoard logs, best/last checkpoints.\n",
        "\n",
        "- Batch evaluation: generate a single summary table (RMSE/MAE + HR@K/NDCG@K) across all variants.\n",
        "\n",
        "- Feature support: plug item features (item_feats.npy) directly into NeuMF’s MLP tower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "432fb183",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "432fb183",
        "outputId": "f38cdb8c-99f5-423f-c0fa-df91900c15f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anime_recomender'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (267/267), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 267 (delta 155), reused 208 (delta 106), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (267/267), 91.62 KiB | 15.27 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n",
            "/content/anime_recomender\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "REPO = \"https://github.com/HenryNVP/anime_recomender.git\"\n",
        "!git clone $REPO\n",
        "\n",
        "import os\n",
        "%cd anime_recomender/\n",
        "\n",
        "!pip -q install -r requirements.txt\n",
        "\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20a13a95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "20a13a95",
        "outputId": "4381f5c1-b1b2-47f5-ed13-9642acb5a875"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb212a06-95a2-4210-a5b6-a2ef6902dca2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb212a06-95a2-4210-a5b6-a2ef6902dca2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving anime.csv to anime.csv\n",
            "Saving rating.csv to rating.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/raw/rating.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import sys, shutil\n",
        "\n",
        "PROJECT_ROOT = os.getcwd()\n",
        "DATA_RAW   = os.path.join(PROJECT_ROOT, \"data/raw\")\n",
        "os.makedirs(DATA_RAW, exist_ok=True)\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()   # select anime.csv and rating.csv\n",
        "\n",
        "shutil.move(\"anime.csv\", \"data/raw/anime.csv\")\n",
        "shutil.move(\"rating.csv\", \"data/raw/rating.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ad4992",
      "metadata": {
        "id": "14ad4992"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "28d352fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d352fb",
        "outputId": "3ff24261-6ce1-426a-e8dc-cb86c0e062c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users: 60970 | Items: 8027 | Ratings: 6314631\n",
            "Splits -> train: 4392123, val: 920565, test: 1001943\n",
            "Saved cleaned data to: data/processed\n",
            "=== Anime metadata (cleaned) ===\n",
            "Total items: 8027\n",
            "Feature matrix shape: (8027, 57)\n",
            "\n",
            "=== Missing values in anime.csv ===\n",
            "Missing genres: 0 (0.00%)\n",
            "Missing types: 0 (0.00%)\n",
            "Missing ratings: 0 (0.00%)\n",
            "\n",
            "=== Numeric fields summary (before scaling) ===\n",
            "\n",
            "episodes:\n",
            "count    8027.000000\n",
            "mean       11.939330\n",
            "std        38.550412\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         2.000000\n",
            "75%        12.000000\n",
            "max      1787.000000\n",
            "Name: episodes, dtype: float64\n",
            "\n",
            "rating:\n",
            "count    8027.000000\n",
            "mean        6.804482\n",
            "std         0.837150\n",
            "min         2.000000\n",
            "25%         6.310000\n",
            "50%         6.830000\n",
            "75%         7.370000\n",
            "max         9.370000\n",
            "Name: rating, dtype: float64\n",
            "\n",
            "members:\n",
            "count    8.027000e+03\n",
            "mean     2.691042e+04\n",
            "std      6.545656e+04\n",
            "min      1.290000e+02\n",
            "25%      1.399000e+03\n",
            "50%      4.372000e+03\n",
            "75%      2.049050e+04\n",
            "max      1.013917e+06\n",
            "Name: members, dtype: float64\n",
            "\n",
            "=== Sanity check: missingness flags ===\n",
            "miss_genre: 4 items flagged (0.05%)\n",
            "miss_type: 0 items flagged (0.00%)\n",
            "miss_rating: 0 items flagged (0.00%)\n",
            "\n",
            "=== Sanity check: numeric feature ranges (scaled) ===\n",
            "episodes: min=0.000, max=1.000, mean=0.006)\n",
            "rating: min=0.000, max=1.000, mean=0.652)\n",
            "members: min=0.000, max=1.000, mean=0.026)\n"
          ]
        }
      ],
      "source": [
        "!python scripts/preprocess_data.py --data_dir data/raw --out_dir data/processed --build_item_features --check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c97241",
      "metadata": {
        "id": "f1c97241"
      },
      "source": [
        "## Baseline Item-based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e95134aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e95134aa",
        "outputId": "309ee0dd-7f5b-408e-839d-752c01ea3c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[val] {'rmse': 1.2460050582885742, 'mae': 0.9429856538772583}\n"
          ]
        }
      ],
      "source": [
        "!python -m src.baselines.itemcf.train --data_dir data/processed --out_prefix runs/itemcf --k 50 --shrink 25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316a6b01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316a6b01",
        "outputId": "2988ac25-ce22-4063-ab16-ea4d0f0b3dfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[rating] test | RMSE=1.2673 MAE=0.9606\n",
            "[ranking] K= 10 | HR=0.6047 NDCG=0.3827 P=0.1140 R=0.1435 MAP=0.0919\n",
            "[ranking] K= 20 | HR=0.6968 NDCG=0.3976 P=0.0863 R=0.2013 MAP=0.0887\n"
          ]
        }
      ],
      "source": [
        "!python -m src.baselines.itemcf.eval --model_prefix runs/itemcf --splits_dir data/processed/splits --split test --k 10,20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194d3001",
      "metadata": {
        "id": "194d3001"
      },
      "source": [
        "## Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b221afd",
      "metadata": {
        "id": "4b221afd"
      },
      "outputs": [],
      "source": [
        "!python -m src.train --config configs/config_mf.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c888b44",
      "metadata": {
        "id": "4c888b44"
      },
      "outputs": [],
      "source": [
        "!python -m src.eval --ckpt runs/neumf/[latest_run]/best.ckpt --config configs/config_mf.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80655ad9",
      "metadata": {
        "id": "80655ad9"
      },
      "source": [
        "## Neural Matrix Factorization (NeuMF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d411c7",
      "metadata": {
        "id": "d8d411c7"
      },
      "outputs": [],
      "source": [
        "!python -m src.train --config configs/config_neumf.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a865f9",
      "metadata": {
        "id": "88a865f9"
      },
      "outputs": [],
      "source": [
        "!python -m src.eval --ckpt runs/neumf/[latest_run]/best.ckpt --config configs/config_neumf.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c792197",
      "metadata": {
        "id": "6c792197"
      },
      "source": [
        "## Batch Training & Evaluation\n",
        "Run shell scripts to train and evaluate variants: MF, NeuMF, Two Tower, and fine tuning Two Tower with Approximate NDCG loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ecfa16c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecfa16c9",
        "outputId": "50f8eedc-f8b9-4f03-cf3d-3eb4157f7627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] (config_twotower) MSE run -> runs/variants/config_twotower/20251015_081335/mse\n",
            "2025-10-15 08:13:37.940175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760516017.960610    3394 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760516017.966658    3394 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760516017.981869    3394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760516017.981892    3394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760516017.981895    3394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760516017.981897    3394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 08:13:37.986372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[run_dir] runs/variants/config_twotower/20251015_081335/mse\n",
            "epoch 01 | train loss (RMSE) 14.5113 | val RMSE 1.3011 | HR@10 0.2467 | NDCG@10 0.0432 | early-stop RMSE best 1.3011\n",
            "epoch 02 | train loss (RMSE) 2.4587 | val RMSE 1.2299 | HR@10 0.1133 | NDCG@10 0.0133 | early-stop RMSE best 1.2299\n",
            "epoch 03 | train loss (RMSE) 2.1609 | val RMSE 1.2226 | HR@10 0.1367 | NDCG@10 0.0182 | early-stop RMSE best 1.2226\n",
            "epoch 04 | train loss (RMSE) 2.0614 | val RMSE 1.2685 | HR@10 0.0367 | NDCG@10 0.0039 | early-stop RMSE best 1.2226\n",
            "epoch 05 | train loss (RMSE) 1.9839 | val RMSE 1.3143 | HR@10 0.0833 | NDCG@10 0.0083 | early-stop RMSE best 1.2226\n",
            "epoch 06 | train loss (RMSE) 1.9309 | val RMSE 1.2945 | HR@10 0.1333 | NDCG@10 0.0145 | early-stop RMSE best 1.2226\n",
            "epoch 07 | train loss (RMSE) 1.8928 | val RMSE 1.2385 | HR@10 0.0967 | NDCG@10 0.0105 | early-stop RMSE best 1.2226\n",
            "epoch 08 | train loss (RMSE) 1.8668 | val RMSE 1.2861 | HR@10 0.1167 | NDCG@10 0.0146 | early-stop RMSE best 1.2226\n",
            "[early-stop] no RMSE improvement for 5 epochs\n",
            "[train] (config_twotower) BPR fine-tune from runs/variants/config_twotower/20251015_081335/mse/best.ckpt -> runs/variants/config_twotower/20251015_081335/mse_to_bpr\n",
            "2025-10-15 08:20:43.988256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760516444.008062    5366 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760516444.014650    5366 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760516444.031202    5366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760516444.031225    5366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760516444.031228    5366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760516444.031230    5366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 08:20:44.035838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[run_dir] runs/variants/config_twotower/20251015_081335/mse_to_bpr\n",
            "[resume] runs/variants/config_twotower/20251015_081335/mse/best.ckpt -> epoch 4 (resetting early-stop metric: ckpt tracked RMSE=1.2226)\n",
            "epoch 01 | train loss (BPR) 0.3864 | val RMSE 1.7272 | HR@10 0.3400 | NDCG@10 0.0770 | early-stop NDCG@10 best 0.0770\n",
            "epoch 02 | train loss (BPR) 0.2625 | val RMSE 2.6996 | HR@10 0.4367 | NDCG@10 0.1112 | early-stop NDCG@10 best 0.1112\n",
            "epoch 03 | train loss (BPR) 0.2460 | val RMSE 3.1912 | HR@10 0.4800 | NDCG@10 0.1166 | early-stop NDCG@10 best 0.1166\n",
            "epoch 04 | train loss (BPR) 0.2395 | val RMSE 3.3274 | HR@10 0.4933 | NDCG@10 0.1209 | early-stop NDCG@10 best 0.1209\n",
            "epoch 05 | train loss (BPR) 0.2330 | val RMSE 3.4185 | HR@10 0.4867 | NDCG@10 0.1202 | early-stop NDCG@10 best 0.1209\n",
            "epoch 06 | train loss (BPR) 0.2306 | val RMSE 3.3219 | HR@10 0.4833 | NDCG@10 0.1195 | early-stop NDCG@10 best 0.1209\n",
            "epoch 07 | train loss (BPR) 0.2295 | val RMSE 3.4913 | HR@10 0.4733 | NDCG@10 0.1164 | early-stop NDCG@10 best 0.1209\n",
            "epoch 08 | train loss (BPR) 0.2288 | val RMSE 3.5027 | HR@10 0.4800 | NDCG@10 0.1144 | early-stop NDCG@10 best 0.1209\n",
            "epoch 09 | train loss (BPR) 0.2283 | val RMSE 3.5817 | HR@10 0.4833 | NDCG@10 0.1186 | early-stop NDCG@10 best 0.1209\n",
            "[early-stop] no NDCG@10 improvement for 5 epochs\n",
            "[done] (config_twotower) Outputs under runs/variants/config_twotower/20251015_081335\n",
            "[train] (config_neumf) MSE run -> runs/variants/config_neumf/20251015_081335/mse\n",
            "2025-10-15 09:22:07.447807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760520127.468774   20654 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760520127.475024   20654 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760520127.491532   20654 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760520127.491565   20654 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760520127.491569   20654 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760520127.491571   20654 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 09:22:07.496640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[run_dir] runs/variants/config_neumf/20251015_081335/mse\n",
            "epoch 01 | train loss (RMSE) 61.3017 | val RMSE 7.4762 | HR@10 0.0567 | NDCG@10 0.0068 | early-stop RMSE best 7.4762\n",
            "epoch 02 | train loss (RMSE) 30.5922 | val RMSE 2.8143 | HR@10 0.1967 | NDCG@10 0.0250 | early-stop RMSE best 2.8143\n",
            "epoch 03 | train loss (RMSE) 5.1772 | val RMSE 1.5530 | HR@10 0.2000 | NDCG@10 0.0429 | early-stop RMSE best 1.5530\n",
            "epoch 04 | train loss (RMSE) 2.2114 | val RMSE 1.2986 | HR@10 0.1567 | NDCG@10 0.0239 | early-stop RMSE best 1.2986\n",
            "epoch 05 | train loss (RMSE) 1.9466 | val RMSE 1.2076 | HR@10 0.1300 | NDCG@10 0.0162 | early-stop RMSE best 1.2076\n",
            "epoch 06 | train loss (RMSE) 1.8744 | val RMSE 1.2055 | HR@10 0.1333 | NDCG@10 0.0180 | early-stop RMSE best 1.2055\n",
            "epoch 07 | train loss (RMSE) 1.8602 | val RMSE 1.2047 | HR@10 0.1367 | NDCG@10 0.0189 | early-stop RMSE best 1.2047\n",
            "epoch 08 | train loss (RMSE) 1.8464 | val RMSE 1.2037 | HR@10 0.1367 | NDCG@10 0.0170 | early-stop RMSE best 1.2037\n",
            "epoch 09 | train loss (RMSE) 1.8072 | val RMSE 1.2030 | HR@10 0.1400 | NDCG@10 0.0173 | early-stop RMSE best 1.2030\n",
            "epoch 10 | train loss (RMSE) 1.7628 | val RMSE 1.2034 | HR@10 0.1400 | NDCG@10 0.0179 | early-stop RMSE best 1.2030\n",
            "epoch 11 | train loss (RMSE) 1.7461 | val RMSE 1.2025 | HR@10 0.1367 | NDCG@10 0.0200 | early-stop RMSE best 1.2025\n",
            "epoch 12 | train loss (RMSE) 1.7344 | val RMSE 1.2015 | HR@10 0.1333 | NDCG@10 0.0178 | early-stop RMSE best 1.2015\n",
            "epoch 13 | train loss (RMSE) 1.7254 | val RMSE 1.2015 | HR@10 0.1400 | NDCG@10 0.0178 | early-stop RMSE best 1.2015\n",
            "epoch 14 | train loss (RMSE) 1.7198 | val RMSE 1.1998 | HR@10 0.1367 | NDCG@10 0.0175 | early-stop RMSE best 1.1998\n",
            "epoch 15 | train loss (RMSE) 1.7164 | val RMSE 1.1998 | HR@10 0.1367 | NDCG@10 0.0182 | early-stop RMSE best 1.1998\n",
            "epoch 16 | train loss (RMSE) 1.7121 | val RMSE 1.1999 | HR@10 0.1367 | NDCG@10 0.0194 | early-stop RMSE best 1.1998\n",
            "epoch 17 | train loss (RMSE) 1.7061 | val RMSE 1.1980 | HR@10 0.1367 | NDCG@10 0.0173 | early-stop RMSE best 1.1980\n",
            "epoch 18 | train loss (RMSE) 1.7018 | val RMSE 1.1966 | HR@10 0.1400 | NDCG@10 0.0201 | early-stop RMSE best 1.1966\n",
            "epoch 19 | train loss (RMSE) 1.7002 | val RMSE 1.1960 | HR@10 0.1367 | NDCG@10 0.0183 | early-stop RMSE best 1.1960\n",
            "epoch 20 | train loss (RMSE) 1.6970 | val RMSE 1.1956 | HR@10 0.1367 | NDCG@10 0.0167 | early-stop RMSE best 1.1956\n",
            "epoch 21 | train loss (RMSE) 1.6944 | val RMSE 1.1948 | HR@10 0.1400 | NDCG@10 0.0192 | early-stop RMSE best 1.1948\n",
            "epoch 22 | train loss (RMSE) 1.6924 | val RMSE 1.1930 | HR@10 0.1400 | NDCG@10 0.0191 | early-stop RMSE best 1.1930\n",
            "epoch 23 | train loss (RMSE) 1.6856 | val RMSE 1.1914 | HR@10 0.1400 | NDCG@10 0.0201 | early-stop RMSE best 1.1914\n",
            "epoch 24 | train loss (RMSE) 1.6778 | val RMSE 1.1878 | HR@10 0.1433 | NDCG@10 0.0190 | early-stop RMSE best 1.1878\n",
            "epoch 25 | train loss (RMSE) 1.6661 | val RMSE 1.1845 | HR@10 0.1467 | NDCG@10 0.0189 | early-stop RMSE best 1.1845\n",
            "epoch 26 | train loss (RMSE) 1.6567 | val RMSE 1.1820 | HR@10 0.1367 | NDCG@10 0.0180 | early-stop RMSE best 1.1820\n",
            "epoch 27 | train loss (RMSE) 1.6466 | val RMSE 1.1796 | HR@10 0.1467 | NDCG@10 0.0206 | early-stop RMSE best 1.1796\n",
            "epoch 28 | train loss (RMSE) 1.6369 | val RMSE 1.1782 | HR@10 0.1467 | NDCG@10 0.0195 | early-stop RMSE best 1.1782\n",
            "epoch 29 | train loss (RMSE) 1.6288 | val RMSE 1.1759 | HR@10 0.1200 | NDCG@10 0.0147 | early-stop RMSE best 1.1759\n",
            "epoch 30 | train loss (RMSE) 1.6225 | val RMSE 1.1747 | HR@10 0.1333 | NDCG@10 0.0176 | early-stop RMSE best 1.1747\n",
            "epoch 31 | train loss (RMSE) 1.6161 | val RMSE 1.1743 | HR@10 0.1467 | NDCG@10 0.0194 | early-stop RMSE best 1.1743\n",
            "epoch 32 | train loss (RMSE) 1.6111 | val RMSE 1.1740 | HR@10 0.1500 | NDCG@10 0.0196 | early-stop RMSE best 1.1740\n",
            "epoch 33 | train loss (RMSE) 1.6073 | val RMSE 1.1727 | HR@10 0.1400 | NDCG@10 0.0204 | early-stop RMSE best 1.1727\n",
            "epoch 34 | train loss (RMSE) 1.6024 | val RMSE 1.1732 | HR@10 0.1400 | NDCG@10 0.0206 | early-stop RMSE best 1.1727\n",
            "epoch 35 | train loss (RMSE) 1.5983 | val RMSE 1.1722 | HR@10 0.1333 | NDCG@10 0.0176 | early-stop RMSE best 1.1722\n",
            "epoch 36 | train loss (RMSE) 1.5940 | val RMSE 1.1722 | HR@10 0.1433 | NDCG@10 0.0194 | early-stop RMSE best 1.1722\n",
            "epoch 37 | train loss (RMSE) 1.5895 | val RMSE 1.1727 | HR@10 0.1400 | NDCG@10 0.0176 | early-stop RMSE best 1.1722\n",
            "epoch 38 | train loss (RMSE) 1.5863 | val RMSE 1.1711 | HR@10 0.1633 | NDCG@10 0.0218 | early-stop RMSE best 1.1711\n",
            "epoch 39 | train loss (RMSE) 1.5827 | val RMSE 1.1718 | HR@10 0.1400 | NDCG@10 0.0201 | early-stop RMSE best 1.1711\n",
            "epoch 40 | train loss (RMSE) 1.5790 | val RMSE 1.1705 | HR@10 0.1600 | NDCG@10 0.0217 | early-stop RMSE best 1.1705\n",
            "epoch 41 | train loss (RMSE) 1.5758 | val RMSE 1.1703 | HR@10 0.1767 | NDCG@10 0.0238 | early-stop RMSE best 1.1703\n",
            "epoch 42 | train loss (RMSE) 1.5711 | val RMSE 1.1696 | HR@10 0.1567 | NDCG@10 0.0220 | early-stop RMSE best 1.1696\n",
            "epoch 43 | train loss (RMSE) 1.5658 | val RMSE 1.1691 | HR@10 0.1700 | NDCG@10 0.0242 | early-stop RMSE best 1.1691\n",
            "epoch 44 | train loss (RMSE) 1.5603 | val RMSE 1.1677 | HR@10 0.1600 | NDCG@10 0.0215 | early-stop RMSE best 1.1677\n",
            "epoch 45 | train loss (RMSE) 1.5553 | val RMSE 1.1667 | HR@10 0.1800 | NDCG@10 0.0239 | early-stop RMSE best 1.1667\n",
            "epoch 46 | train loss (RMSE) 1.5503 | val RMSE 1.1658 | HR@10 0.1733 | NDCG@10 0.0242 | early-stop RMSE best 1.1658\n",
            "epoch 47 | train loss (RMSE) 1.5433 | val RMSE 1.1653 | HR@10 0.1800 | NDCG@10 0.0222 | early-stop RMSE best 1.1653\n",
            "epoch 48 | train loss (RMSE) 1.5369 | val RMSE 1.1664 | HR@10 0.1700 | NDCG@10 0.0212 | early-stop RMSE best 1.1653\n",
            "epoch 49 | train loss (RMSE) 1.5317 | val RMSE 1.1648 | HR@10 0.1700 | NDCG@10 0.0212 | early-stop RMSE best 1.1648\n",
            "epoch 50 | train loss (RMSE) 1.5254 | val RMSE 1.1638 | HR@10 0.1533 | NDCG@10 0.0199 | early-stop RMSE best 1.1638\n",
            "epoch 51 | train loss (RMSE) 1.5208 | val RMSE 1.1635 | HR@10 0.1533 | NDCG@10 0.0203 | early-stop RMSE best 1.1635\n",
            "epoch 52 | train loss (RMSE) 1.5161 | val RMSE 1.1638 | HR@10 0.1533 | NDCG@10 0.0183 | early-stop RMSE best 1.1635\n",
            "epoch 53 | train loss (RMSE) 1.5101 | val RMSE 1.1630 | HR@10 0.1633 | NDCG@10 0.0209 | early-stop RMSE best 1.1630\n",
            "epoch 54 | train loss (RMSE) 1.5054 | val RMSE 1.1624 | HR@10 0.1400 | NDCG@10 0.0174 | early-stop RMSE best 1.1624\n",
            "epoch 55 | train loss (RMSE) 1.5030 | val RMSE 1.1620 | HR@10 0.1667 | NDCG@10 0.0230 | early-stop RMSE best 1.1620\n",
            "epoch 56 | train loss (RMSE) 1.4982 | val RMSE 1.1615 | HR@10 0.1400 | NDCG@10 0.0191 | early-stop RMSE best 1.1615\n",
            "epoch 57 | train loss (RMSE) 1.4920 | val RMSE 1.1678 | HR@10 0.1500 | NDCG@10 0.0200 | early-stop RMSE best 1.1615\n",
            "epoch 58 | train loss (RMSE) 1.4891 | val RMSE 1.1610 | HR@10 0.1500 | NDCG@10 0.0202 | early-stop RMSE best 1.1610\n",
            "epoch 59 | train loss (RMSE) 1.4828 | val RMSE 1.1628 | HR@10 0.1633 | NDCG@10 0.0236 | early-stop RMSE best 1.1610\n",
            "epoch 60 | train loss (RMSE) 1.4785 | val RMSE 1.1610 | HR@10 0.1500 | NDCG@10 0.0199 | early-stop RMSE best 1.1610\n",
            "[done] (config_neumf) Outputs under runs/variants/config_neumf/20251015_081335\n",
            "[train] (config_mf) MSE run -> runs/variants/config_mf/20251015_081335/mse\n",
            "2025-10-15 10:12:17.799329: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760523137.819427   34664 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760523137.825598   34664 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760523137.841192   34664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760523137.841216   34664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760523137.841219   34664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760523137.841221   34664 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 10:12:17.845821: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[run_dir] runs/variants/config_mf/20251015_081335/mse\n",
            "epoch 01 | train loss (RMSE) 63.1194 | val RMSE 7.9196 | HR@10 0.1600 | NDCG@10 0.0229 | early-stop RMSE best 7.9196\n",
            "epoch 02 | train loss (RMSE) 62.3554 | val RMSE 7.8492 | HR@10 0.3033 | NDCG@10 0.0592 | early-stop RMSE best 7.8492\n",
            "epoch 03 | train loss (RMSE) 60.7235 | val RMSE 7.7014 | HR@10 0.3167 | NDCG@10 0.0628 | early-stop RMSE best 7.7014\n",
            "epoch 04 | train loss (RMSE) 57.7733 | val RMSE 7.4576 | HR@10 0.3567 | NDCG@10 0.0691 | early-stop RMSE best 7.4576\n",
            "epoch 05 | train loss (RMSE) 53.4559 | val RMSE 7.1146 | HR@10 0.3767 | NDCG@10 0.0767 | early-stop RMSE best 7.1146\n",
            "epoch 06 | train loss (RMSE) 47.9593 | val RMSE 6.6783 | HR@10 0.3933 | NDCG@10 0.0817 | early-stop RMSE best 6.6783\n",
            "epoch 07 | train loss (RMSE) 41.6199 | val RMSE 6.1608 | HR@10 0.4300 | NDCG@10 0.0896 | early-stop RMSE best 6.1608\n",
            "epoch 08 | train loss (RMSE) 34.8594 | val RMSE 5.5796 | HR@10 0.4267 | NDCG@10 0.0924 | early-stop RMSE best 5.5796\n",
            "epoch 09 | train loss (RMSE) 28.1284 | val RMSE 4.9572 | HR@10 0.4400 | NDCG@10 0.0949 | early-stop RMSE best 4.9572\n",
            "epoch 10 | train loss (RMSE) 21.8501 | val RMSE 4.3211 | HR@10 0.4400 | NDCG@10 0.0971 | early-stop RMSE best 4.3211\n",
            "epoch 11 | train loss (RMSE) 16.3680 | val RMSE 3.7024 | HR@10 0.4433 | NDCG@10 0.1047 | early-stop RMSE best 3.7024\n",
            "epoch 12 | train loss (RMSE) 11.8940 | val RMSE 3.1332 | HR@10 0.4567 | NDCG@10 0.1076 | early-stop RMSE best 3.1332\n",
            "epoch 13 | train loss (RMSE) 8.4918 | val RMSE 2.6420 | HR@10 0.4500 | NDCG@10 0.1085 | early-stop RMSE best 2.6420\n",
            "epoch 14 | train loss (RMSE) 6.0828 | val RMSE 2.2477 | HR@10 0.4533 | NDCG@10 0.1108 | early-stop RMSE best 2.2477\n",
            "epoch 15 | train loss (RMSE) 4.4828 | val RMSE 1.9541 | HR@10 0.4433 | NDCG@10 0.1087 | early-stop RMSE best 1.9541\n",
            "epoch 16 | train loss (RMSE) 3.4727 | val RMSE 1.7495 | HR@10 0.4233 | NDCG@10 0.1065 | early-stop RMSE best 1.7495\n",
            "epoch 17 | train loss (RMSE) 2.8528 | val RMSE 1.6130 | HR@10 0.4100 | NDCG@10 0.0993 | early-stop RMSE best 1.6130\n",
            "epoch 18 | train loss (RMSE) 2.4712 | val RMSE 1.5230 | HR@10 0.3967 | NDCG@10 0.0980 | early-stop RMSE best 1.5230\n",
            "epoch 19 | train loss (RMSE) 2.2312 | val RMSE 1.4625 | HR@10 0.3900 | NDCG@10 0.0943 | early-stop RMSE best 1.4625\n",
            "epoch 20 | train loss (RMSE) 2.0728 | val RMSE 1.4206 | HR@10 0.3533 | NDCG@10 0.0883 | early-stop RMSE best 1.4206\n",
            "epoch 21 | train loss (RMSE) 1.9634 | val RMSE 1.3904 | HR@10 0.3367 | NDCG@10 0.0844 | early-stop RMSE best 1.3904\n",
            "epoch 22 | train loss (RMSE) 1.8843 | val RMSE 1.3680 | HR@10 0.3233 | NDCG@10 0.0815 | early-stop RMSE best 1.3680\n",
            "epoch 23 | train loss (RMSE) 1.8257 | val RMSE 1.3509 | HR@10 0.3200 | NDCG@10 0.0754 | early-stop RMSE best 1.3509\n",
            "epoch 24 | train loss (RMSE) 1.7805 | val RMSE 1.3376 | HR@10 0.3067 | NDCG@10 0.0718 | early-stop RMSE best 1.3376\n",
            "epoch 25 | train loss (RMSE) 1.7460 | val RMSE 1.3269 | HR@10 0.3000 | NDCG@10 0.0669 | early-stop RMSE best 1.3269\n",
            "epoch 26 | train loss (RMSE) 1.7178 | val RMSE 1.3183 | HR@10 0.2867 | NDCG@10 0.0637 | early-stop RMSE best 1.3183\n",
            "epoch 27 | train loss (RMSE) 1.6946 | val RMSE 1.3112 | HR@10 0.2733 | NDCG@10 0.0553 | early-stop RMSE best 1.3112\n",
            "epoch 28 | train loss (RMSE) 1.6760 | val RMSE 1.3052 | HR@10 0.2500 | NDCG@10 0.0484 | early-stop RMSE best 1.3052\n",
            "epoch 29 | train loss (RMSE) 1.6604 | val RMSE 1.3002 | HR@10 0.2233 | NDCG@10 0.0434 | early-stop RMSE best 1.3002\n",
            "epoch 30 | train loss (RMSE) 1.6469 | val RMSE 1.2958 | HR@10 0.2233 | NDCG@10 0.0417 | early-stop RMSE best 1.2958\n",
            "epoch 31 | train loss (RMSE) 1.6351 | val RMSE 1.2921 | HR@10 0.2200 | NDCG@10 0.0408 | early-stop RMSE best 1.2921\n",
            "epoch 32 | train loss (RMSE) 1.6255 | val RMSE 1.2889 | HR@10 0.2133 | NDCG@10 0.0393 | early-stop RMSE best 1.2889\n",
            "epoch 33 | train loss (RMSE) 1.6171 | val RMSE 1.2860 | HR@10 0.2033 | NDCG@10 0.0380 | early-stop RMSE best 1.2860\n",
            "epoch 34 | train loss (RMSE) 1.6093 | val RMSE 1.2835 | HR@10 0.1967 | NDCG@10 0.0370 | early-stop RMSE best 1.2835\n",
            "epoch 35 | train loss (RMSE) 1.6023 | val RMSE 1.2812 | HR@10 0.1967 | NDCG@10 0.0366 | early-stop RMSE best 1.2812\n",
            "epoch 36 | train loss (RMSE) 1.5969 | val RMSE 1.2793 | HR@10 0.1967 | NDCG@10 0.0363 | early-stop RMSE best 1.2793\n",
            "epoch 37 | train loss (RMSE) 1.5917 | val RMSE 1.2774 | HR@10 0.1933 | NDCG@10 0.0358 | early-stop RMSE best 1.2774\n",
            "epoch 38 | train loss (RMSE) 1.5869 | val RMSE 1.2758 | HR@10 0.1933 | NDCG@10 0.0352 | early-stop RMSE best 1.2758\n",
            "epoch 39 | train loss (RMSE) 1.5829 | val RMSE 1.2743 | HR@10 0.1900 | NDCG@10 0.0345 | early-stop RMSE best 1.2743\n",
            "epoch 40 | train loss (RMSE) 1.5785 | val RMSE 1.2729 | HR@10 0.1900 | NDCG@10 0.0345 | early-stop RMSE best 1.2729\n",
            "epoch 41 | train loss (RMSE) 1.5754 | val RMSE 1.2717 | HR@10 0.1800 | NDCG@10 0.0334 | early-stop RMSE best 1.2717\n",
            "epoch 42 | train loss (RMSE) 1.5721 | val RMSE 1.2705 | HR@10 0.1800 | NDCG@10 0.0334 | early-stop RMSE best 1.2705\n",
            "epoch 43 | train loss (RMSE) 1.5690 | val RMSE 1.2695 | HR@10 0.1700 | NDCG@10 0.0326 | early-stop RMSE best 1.2695\n",
            "epoch 44 | train loss (RMSE) 1.5664 | val RMSE 1.2685 | HR@10 0.1700 | NDCG@10 0.0326 | early-stop RMSE best 1.2685\n",
            "epoch 45 | train loss (RMSE) 1.5634 | val RMSE 1.2676 | HR@10 0.1667 | NDCG@10 0.0314 | early-stop RMSE best 1.2676\n",
            "epoch 46 | train loss (RMSE) 1.5615 | val RMSE 1.2668 | HR@10 0.1633 | NDCG@10 0.0304 | early-stop RMSE best 1.2668\n",
            "epoch 47 | train loss (RMSE) 1.5591 | val RMSE 1.2660 | HR@10 0.1567 | NDCG@10 0.0300 | early-stop RMSE best 1.2660\n",
            "epoch 48 | train loss (RMSE) 1.5572 | val RMSE 1.2652 | HR@10 0.1567 | NDCG@10 0.0300 | early-stop RMSE best 1.2652\n",
            "epoch 49 | train loss (RMSE) 1.5556 | val RMSE 1.2644 | HR@10 0.1567 | NDCG@10 0.0300 | early-stop RMSE best 1.2644\n",
            "epoch 50 | train loss (RMSE) 1.5537 | val RMSE 1.2638 | HR@10 0.1567 | NDCG@10 0.0300 | early-stop RMSE best 1.2638\n",
            "epoch 51 | train loss (RMSE) 1.5520 | val RMSE 1.2631 | HR@10 0.1567 | NDCG@10 0.0304 | early-stop RMSE best 1.2631\n",
            "epoch 52 | train loss (RMSE) 1.5500 | val RMSE 1.2625 | HR@10 0.1567 | NDCG@10 0.0304 | early-stop RMSE best 1.2625\n",
            "epoch 53 | train loss (RMSE) 1.5486 | val RMSE 1.2619 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2619\n",
            "epoch 54 | train loss (RMSE) 1.5473 | val RMSE 1.2614 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2614\n",
            "epoch 55 | train loss (RMSE) 1.5457 | val RMSE 1.2609 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2609\n",
            "epoch 56 | train loss (RMSE) 1.5446 | val RMSE 1.2603 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2603\n",
            "epoch 57 | train loss (RMSE) 1.5430 | val RMSE 1.2598 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2598\n",
            "epoch 58 | train loss (RMSE) 1.5420 | val RMSE 1.2594 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2594\n",
            "epoch 59 | train loss (RMSE) 1.5405 | val RMSE 1.2589 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2589\n",
            "epoch 60 | train loss (RMSE) 1.5396 | val RMSE 1.2585 | HR@10 0.1567 | NDCG@10 0.0302 | early-stop RMSE best 1.2585\n",
            "[done] (config_mf) Outputs under runs/variants/config_mf/20251015_081335\n"
          ]
        }
      ],
      "source": [
        "!bash ./scripts/train_variants.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "718QYQPuWUvZ",
      "metadata": {
        "id": "718QYQPuWUvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a5b524-97f2-4803-8343-f2955b12d988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[eval] config_twotower (mse) -> runs/evaluation/20251015_110134/config_twotower__mse.json\n",
            "2025-10-15 11:01:37.000399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760526097.022111   48462 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760526097.028712   48462 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760526097.044835   48462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526097.044857   48462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526097.044859   48462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526097.044861   48462 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 11:01:37.049676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[rating] test | RMSE=1.2257 MAE=0.9394\n",
            "[ranking] K= 10 | HR=0.1372 NDCG=0.0160 P=0.0154 R=0.0210 MAP=0.0047\n",
            "[ranking] K= 20 | HR=0.1584 NDCG=0.0158 P=0.0095 R=0.0241 MAP=0.0043\n",
            "[saved] metrics -> runs/evaluation/20251015_110134/config_twotower__mse.json\n",
            "[eval] config_twotower (mse_to_bpr) -> runs/evaluation/20251015_110134/config_twotower__mse_to_bpr.json\n",
            "2025-10-15 11:04:41.555796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760526281.576418   49285 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760526281.582529   49285 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760526281.597875   49285 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526281.597897   49285 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526281.597900   49285 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526281.597902   49285 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 11:04:41.602569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[rating] test | RMSE=3.3067 MAE=2.8163\n",
            "[ranking] K= 10 | HR=0.4154 NDCG=0.0843 P=0.0543 R=0.0893 MAP=0.0403\n",
            "[ranking] K= 20 | HR=0.5787 NDCG=0.1019 P=0.0461 R=0.1439 MAP=0.0425\n",
            "[saved] metrics -> runs/evaluation/20251015_110134/config_twotower__mse_to_bpr.json\n",
            "[eval] config_neumf (mse) -> runs/evaluation/20251015_110134/config_neumf__mse.json\n",
            "2025-10-15 11:07:43.923938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760526463.943688   50097 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760526463.949636   50097 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760526463.964750   50097 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526463.964771   50097 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526463.964772   50097 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526463.964774   50097 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 11:07:43.969254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[rating] test | RMSE=1.1662 MAE=0.8815\n",
            "[ranking] K= 10 | HR=0.1275 NDCG=0.0157 P=0.0145 R=0.0193 MAP=0.0050\n",
            "[ranking] K= 20 | HR=0.2336 NDCG=0.0233 P=0.0152 R=0.0392 MAP=0.0060\n",
            "[saved] metrics -> runs/evaluation/20251015_110134/config_neumf__mse.json\n",
            "[eval] config_mf (mse) -> runs/evaluation/20251015_110134/config_mf__mse.json\n",
            "2025-10-15 11:10:08.360593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760526608.381119   50753 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760526608.387406   50753 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760526608.402868   50753 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526608.402897   50753 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526608.402899   50753 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760526608.402900   50753 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 11:10:08.407503: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[rating] test | RMSE=1.2743 MAE=0.9731\n",
            "[ranking] K= 10 | HR=0.1416 NDCG=0.0230 P=0.0160 R=0.0218 MAP=0.0097\n",
            "[ranking] K= 20 | HR=0.2804 NDCG=0.0330 P=0.0181 R=0.0485 MAP=0.0107\n",
            "[saved] metrics -> runs/evaluation/20251015_110134/config_mf__mse.json\n",
            "[eval] itemcf (baseline) -> runs/evaluation/20251015_110134/itemcf__baseline.json\n",
            "[saved] runs/evaluation/20251015_110134/itemcf__baseline.json\n",
            "[rating] test | RMSE=1.2516 MAE=0.9464\n",
            "[ranking] K= 10 | HR=0.6209 NDCG=0.1779 P=0.1179 R=0.1498 MAP=0.0966\n",
            "[ranking] K= 20 | HR=0.7085 NDCG=0.1895 P=0.0889 R=0.2091 MAP=0.0933\n",
            "Model           | Variant    | RMSE   | MAE    | HR@10  | NDCG@10 | HR@20  | NDCG@20\n",
            "----------------+------------+--------+--------+--------+---------+--------+--------\n",
            "config_mf       | mse        | 1.2743 | 0.9731 | 0.1416 | 0.0230  | 0.2804 | 0.0330 \n",
            "config_neumf    | mse        | 1.1662 | 0.8815 | 0.1275 | 0.0157  | 0.2336 | 0.0233 \n",
            "config_twotower | mse        | 1.2257 | 0.9394 | 0.1372 | 0.0160  | 0.1584 | 0.0158 \n",
            "config_twotower | mse_to_bpr | 3.3067 | 2.8163 | 0.4154 | 0.0843  | 0.5787 | 0.1019 \n",
            "itemcf          | baseline   | 1.2516 | 0.9464 | 0.6209 | 0.1779  | 0.7085 | 0.1895 \n",
            "\n",
            "[summary] metrics table -> runs/evaluation/20251015_110134/summary.tsv\n",
            "[done] evaluations stored in runs/evaluation/20251015_110134\n"
          ]
        }
      ],
      "source": [
        "!bash ./scripts/evaluate_all.sh"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}